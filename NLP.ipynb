{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e71b291-dbab-45a0-b820-5306bd10cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTALLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eaf41b3-c21c-419c-a3c0-d81040e1e846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\allam\\appdata\\roaming\\python\\python312\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\allam\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\allam\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\allam\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\allam\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\allam\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa984ad-f805-4bc1-a054-7bf75d63b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd83640-a216-4245-b237-4f69547f5be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\allam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\allam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nltk.corpus\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02d6f7a-3692-4087-bc62-89a0c6847577",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd93a07-fc7a-4c86-8f92-b4c5c0c623f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentence=\" demonstration for tokenzation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54ff6ca5-86d9-406a-bed3-0b40a5de7d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef7f70e-1d60-454e-9f01-452a1e41b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80312266-494b-4d86-873a-02b699175310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', '!', 'How', 'are', 'you', 'doing', 'today', '?', 'hello', 'are', 'you', 'you']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Hello! How are you doing today? hello are you you\"\n",
    "tokens = word_tokenize(sentence)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65720d8e-af0b-459a-ab49-bc79fb860756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "427e5a9d-a4e0-4005-a8d7-cf890e21632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e17eabc6-23b9-4bbc-980d-fe5413477aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'you': 3, 'hello': 2, 'are': 2, '!': 1, 'how': 1, 'doing': 1, 'today': 1, '?': 1})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in tokens:\n",
    "    fdist[word.lower()]+=1\n",
    "fdist    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a5a1a2f-8bb3-4a1b-af78-7bd86ca3df16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist['you']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "315c9f3c-b023-4189-8324-4fb9dad6250c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cdc1913-2613-4f8b-9401-0d2b3fc302ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you', 3), ('hello', 2), ('are', 2)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_top3 = fdist.most_common(3)\n",
    "fdist_top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58f07a45-1073-4974-adc4-ed69521771b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import blankline_tokenize\n",
    "ablank = blankline_tokenize(Sentence)\n",
    "len(ablank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd1b520-7064-47ea-9239-413e853fd319",
   "metadata": {},
   "outputs": [],
   "source": [
    "2.GROUPING TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8df6b929-e472-4af2-ae15-f8b306a38b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams,trigrams,ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3afadfa-0a09-4cb9-92ca-a3c2273bf9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'intelligence',\n",
       " 'is',\n",
       " 'transforming',\n",
       " 'industries',\n",
       " 'by',\n",
       " 'automating',\n",
       " 'tasks',\n",
       " 'and',\n",
       " 'enabling',\n",
       " 'smarter',\n",
       " 'decision-making',\n",
       " 'worldwide']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string= \"Artificial intelligence is transforming industries by automating tasks and enabling smarter decision-making worldwide\"\n",
    "qtokens= nltk.word_tokenize(string)\n",
    "qtokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "426a3516-30f6-469f-9b39-b15805d0e38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Artificial', 'intelligence'),\n",
       " ('intelligence', 'is'),\n",
       " ('is', 'transforming'),\n",
       " ('transforming', 'industries'),\n",
       " ('industries', 'by'),\n",
       " ('by', 'automating'),\n",
       " ('automating', 'tasks'),\n",
       " ('tasks', 'and'),\n",
       " ('and', 'enabling'),\n",
       " ('enabling', 'smarter'),\n",
       " ('smarter', 'decision-making'),\n",
       " ('decision-making', 'worldwide')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qbigrams = list(nltk.bigrams(qtokens))\n",
    "qbigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acb6c649-f3a6-4a67-8799-c95c3bf48462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Artificial', 'intelligence', 'is'),\n",
       " ('intelligence', 'is', 'transforming'),\n",
       " ('is', 'transforming', 'industries'),\n",
       " ('transforming', 'industries', 'by'),\n",
       " ('industries', 'by', 'automating'),\n",
       " ('by', 'automating', 'tasks'),\n",
       " ('automating', 'tasks', 'and'),\n",
       " ('tasks', 'and', 'enabling'),\n",
       " ('and', 'enabling', 'smarter'),\n",
       " ('enabling', 'smarter', 'decision-making'),\n",
       " ('smarter', 'decision-making', 'worldwide')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtrigrams = list(nltk.trigrams(qtokens))\n",
    "qtrigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6755a2a4-8e59-4190-923a-728f715cf543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Artificial', 'intelligence', 'is', 'transforming', 'industries'),\n",
       " ('intelligence', 'is', 'transforming', 'industries', 'by'),\n",
       " ('is', 'transforming', 'industries', 'by', 'automating'),\n",
       " ('transforming', 'industries', 'by', 'automating', 'tasks'),\n",
       " ('industries', 'by', 'automating', 'tasks', 'and'),\n",
       " ('by', 'automating', 'tasks', 'and', 'enabling'),\n",
       " ('automating', 'tasks', 'and', 'enabling', 'smarter'),\n",
       " ('tasks', 'and', 'enabling', 'smarter', 'decision-making'),\n",
       " ('and', 'enabling', 'smarter', 'decision-making', 'worldwide')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qngrams = list(nltk.ngrams(qtokens,5))\n",
    "qngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc43871-2e72-48d0-b930-93fef12a07da",
   "metadata": {},
   "outputs": [],
   "source": [
    "3.STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "471fd8ca-195e-47b7-8d92-a610bf32fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pst=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8f2c62b-5cf8-4a5c-afcb-1e27acf07a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"having\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "932711af-df6e-44cd-8e48-90e05072d895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:give\n",
      "given:given\n",
      "gave:gave\n"
     ]
    }
   ],
   "source": [
    "wts=[\"give\",\"giving\",\"given\",\"gave\"]\n",
    "for words in wts:\n",
    "    print(words + \":\" + pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bb4b487-4865-4671-95a0-101ab448374e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:giv\n",
      "giving:giv\n",
      "given:giv\n",
      "gave:gav\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lst=LancasterStemmer()\n",
    "for words in wts:\n",
    "    print(words + \":\" + lst.stem(words))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1065dbac-46c8-4347-8e78-2340a4ab18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "sbst=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "027215e6-dd32-4e0c-821d-5402f9625426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:give\n",
      "given:given\n",
      "gave:gave\n"
     ]
    }
   ],
   "source": [
    "for words in wts:\n",
    "    print(words + \":\" + sbst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d1072-a84d-4c57-9173-af06db3dd5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "4.LEMMATIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b1186c7-742f-42b2-b376-7cb80b0b458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\allam\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01277f23-43b8-4b9b-837e-195249657b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wl=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c5137c6-f722-4b9e-bef3-dcb76dc28c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.lemmatize('corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a3e8027-1233-423f-8b2c-e71d74e45569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:giving\n",
      "given:given\n",
      "gave:gave\n"
     ]
    }
   ],
   "source": [
    "for words in wts:\n",
    "    print(words + \":\" + wl.lemmatize(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc680752-db3f-424e-8230-275fc7d82ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "5.STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ab7c4de-2ca2-4c15-bed8-c768d529d4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\allam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70c516e7-c09e-47f9-bd7d-7071cac45349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8a224d31-d947-49bd-bcb6-07a023a1d772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "60ad9949-78dc-4cdf-bf21-2dd5825426e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d7baaf-225d-4ae0-9bf0-0d1c7c389a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "6.REMOVING PUNCTUATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "981e6604-cb1b-4c7b-933f-4ee0d7749b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pu = re.compile(r'[-.?!,:;()|0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b58e7ee5-60b6-4bc2-8ef5-ed6b3817472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=[]\n",
    "for words in tokens:\n",
    "    word=pu.sub(\"\",words)\n",
    "    if len(words)>0:\n",
    "        pp.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "433595e0-334f-402f-9b10-cdf204daeec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " '',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " 'doing',\n",
       " 'today',\n",
       " '',\n",
       " 'hello',\n",
       " 'are',\n",
       " 'you',\n",
       " 'you']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0414f7-eff5-4054-b046-9ffccbf26b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "7.POS TAGS(PARTS OF SPEECH TAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0402a440-5c3f-48a0-bc37-1dafe718642d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\allam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "66a01ca4-62d9-4db1-9fbc-6efc3aa9487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "se =\"Timothy is a natural when it comes to drawing\"\n",
    "set=word_tokenize(se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b0330919-bef9-4342-a5a9-14b23335479f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Timothy', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('a', 'DT')]\n",
      "[('natural', 'JJ')]\n",
      "[('when', 'WRB')]\n",
      "[('it', 'PRP')]\n",
      "[('comes', 'VBZ')]\n",
      "[('to', 'TO')]\n",
      "[('drawing', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "for tokens in set:\n",
    "    print(nltk.pos_tag([tokens]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5ea4305b-a4b9-4e52-9263-65e0ed7a05c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('john', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('eating', 'VBG')]\n",
      "[('a', 'DT')]\n",
      "[('delicious', 'JJ')]\n",
      "[('cake', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "se2 = \"john is eating a delicious cake\"\n",
    "set2=word_tokenize(se2)\n",
    "for tokens in set2:\n",
    "    print(nltk.pos_tag([tokens]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "315551b3-3264-4608-8bce-a0a2082aef83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP')]\n",
      "[('am', 'VBP')]\n",
      "[('learning', 'VBG')]\n",
      "[('NLP', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "se3 = \" I am learning NLP\"\n",
    "set3=word_tokenize(se3)\n",
    "for tokens in set3:\n",
    "    print(nltk.pos_tag([tokens]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c07525-479b-402a-8e26-f016597668d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "8.CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b6a27cd2-a43f-4c61-aa02-7196c6ecb8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     C:\\Users\\allam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5bc29592-41ac-4b5e-83e9-207e2ca6abc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\allam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "61ea17ef-28da-4b2a-b243-67183cdfc120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d5a3453f-41f2-4f22-b0bf-862a10caf1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_se= \" The US President stays in the WHITE HOUSE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f7fcbdb6-e0a4-4b93-875f-cddf7863e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "net= word_tokenize(ne_se)\n",
    "neta = nltk.pos_tag(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e7f2f77e-c154-4e11-a448-81169c8fb331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  (ORGANIZATION US/NNP)\n",
      "  President/NNP\n",
      "  stays/VBZ\n",
      "  in/IN\n",
      "  the/DT\n",
      "  (FACILITY WHITE/NNP HOUSE/NNP))\n"
     ]
    }
   ],
   "source": [
    "ner = ne_chunk(neta)\n",
    "print(ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0e08461e-f597-4850-9d1a-cb9433c97f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('big', 'JJ'),\n",
       " ('cat', 'NN'),\n",
       " ('ate', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('little', 'JJ'),\n",
       " ('mouse', 'NN'),\n",
       " ('who', 'WP'),\n",
       " ('was', 'VBD'),\n",
       " ('after', 'IN'),\n",
       " ('fresh', 'JJ'),\n",
       " ('cheese', 'NN')]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = \" The big cat ate the little mouse who was after fresh cheese \"\n",
    "nt = nltk.pos_tag(word_tokenize(new))\n",
    "nt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "54a9e676-f5f0-4c65-828b-e26ee52bf5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_np = r\"NP:{ <DT>?<JJ>*<NN>}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "525f5f37-b561-4bca-89c5-e1e80493b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = nltk.RegexpParser(g_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6a39dd8c-32ed-458b-a4af-d5dfddb4b83c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'svgling'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\formatters.py:347\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    345\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m method()\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\nltk\\tree\\tree.py:782\u001b[0m, in \u001b[0;36mTree._repr_svg_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_repr_svg_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 782\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msvgling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_tree\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw_tree(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_repr_svg_()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'svgling'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [Tree('NP', [('The', 'DT'), ('big', 'JJ'), ('cat', 'NN')]), ('ate', 'VBD'), Tree('NP', [('the', 'DT'), ('little', 'JJ'), ('mouse', 'NN')]), ('who', 'WP'), ('was', 'VBD'), ('after', 'IN'), Tree('NP', [('fresh', 'JJ'), ('cheese', 'NN')])])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr = cp.parse(nt)\n",
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e50f6b-0385-4179-9eae-0eea436b0c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
